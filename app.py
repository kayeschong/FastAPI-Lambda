# coding: utf8
from fastapi import FastAPI, Body, Query
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import spacy  # type: ignore
from spacy.matcher import Matcher  # type: ignore
from typing import List, Dict, Tuple, Any
from mangum import Mangum

app = FastAPI(
    title="Matcher Service",
    description="Using FastAPI to reproduce matcher backend from <https://explosion.ai/demos/matcher>, based on <https://github.com/explosion/spacy-services>."
)

origins = [
    "http://localhost",
    "http://localhost:8080",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

INSTALLED_MODELS: Tuple[str] = (
    "en_core_web_sm",
)

MODELS: Dict[str, Any] = {
    model_name: spacy.load(model_name)
    for model_name in INSTALLED_MODELS
}


class MatchData(BaseModel):
    text: str
    # Pattern format changed for spacy v3
    pattern: List[
        List[
            Dict[str, str]
        ]
    ]


def get_model_desc(nlp: Any, model_name: str) -> str:
    """Get human-readable model name, language name and version."""
    lang_cls = spacy.util.get_lang_class(nlp.lang)
    lang_name = lang_cls.__name__
    model_version = nlp.meta["version"]
    return f"{lang_name} - {model_name} (v{model_version})"


@app.get("/models")
def models() -> Dict[str, str]:
    """Get human-readable model name, language name and version."""
    return {name: get_model_desc(nlp, name) for name, nlp in MODELS.items()}


@app.post("/match")
def match(
    model: str = Query(..., enum=INSTALLED_MODELS),
    data: MatchData = Body(
        ...,  # required param
        example={
            "text": "A match is a tool for starting a fire. Typically, modern matches are made of small wooden sticks or stiff paper. One end is coated with a material that can be ignited by frictional heat generated by striking the match against a suitable surface. Wooden matches are packaged in matchboxes, and paper matches are partially cut into rows and stapled into matchbooks.",
            "pattern": [
                [{"POS": "ADJ"}, {"OP": "?"}],
                [{"LEMMA": "match"}, {"POS": "NOUN"}],
                [{"LEMMA": "be"}]
            ]
        }
    ),
) -> Dict[str, List[dict]]:
    """Match text tokens based on input pattern"""
    nlp = MODELS[model]

    matcher = Matcher(nlp.vocab)
    matcher.add("PATTERN", data.pattern)  # pattern args changed for v3

    doc = nlp(data.text)
    tokens: List[dict] = []
    matches: List[dict] = []
    match_tokens = set()

    for _, start, end in matcher(doc):
        if start >= end:  # filter out null matches or results of weird bug
            continue
        span = doc[start:end]
        if span[0].i in match_tokens:  # filter out overlaps
            continue
        match_tokens.update([t.i for t in span])
        matches.append(
            {"start": span.start_char, "end": span.end_char, "label": "MATCH"}
        )

    for t in doc:
        start = t.idx
        end = t.idx + len(t.text)
        label = "MATCH" if t.i in match_tokens else "TOKEN"
        tokens.append({"start": start, "end": end, "label": label})

    return {"matches": matches, "tokens": tokens}


# Creates asgi handler for AWS Lambda
handler = Mangum(app)
